# Production Docker Compose for BankingLLM system

services:
  # Production Ollama service
  ollama:
    deploy:
      resources:
        limits:
          memory: 6G
          cpus: '2.0'
        reservations:
          memory: 4G
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Production Web service
  banking-llm-web:
    volumes:
      # Only exports directory for generated Excel files
      - ./data/exports:/app/data/exports:rw
      # No src mount in production
      # No database mount - database is pre-built in image
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - LLM_MODEL=qwen2.5:7b
      - LOG_LEVEL=WARNING
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

